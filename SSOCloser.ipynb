{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLC1c7eNwT/Yp4afX7tN1W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ESHA1101/SSOC_Pneumonia-detection-using-x-rays/blob/main/SSOCloser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e53rSWFEHcYA",
        "outputId": "9683e3bc-ca89-474a-a6c2-6b11eff549fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imgaug.augmenters as ia\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
      ],
      "metadata": {
        "id": "HFQneukZMT0A"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_paths = Path('drive/MyDrive/chest_xray')"
      ],
      "metadata": {
        "id": "i_mEKYC3NgRE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = data_paths / \"train\"\n",
        "val_dir = data_paths / \"val\"\n",
        "test_dir = data_paths / \"test\"\n"
      ],
      "metadata": {
        "id": "aM3rzBiqXwp4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_cases_dir = train_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = train_dir / 'PNEUMONIA'"
      ],
      "metadata": {
        "id": "G5e8NUC0YRL4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg') "
      ],
      "metadata": {
        "id": "B1jxhT9wUFOW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=[]\n",
        "for i in normal_cases:\n",
        "    train_data.append((i,0))          #normal cases will be labeled as 0\n",
        "for i in pneumonia_cases:             #pneumonia cases will be labelled as 1\n",
        "    train_data.append((i,1))\n",
        "print(train_data)\n"
      ],
      "metadata": {
        "id": "1WQIJaDgUemo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe=pd.DataFrame(train_data, columns=['Image','Label'])\n"
      ],
      "metadata": {
        "id": "798T-lXbVGED"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_cases_dir = val_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg') \n",
        "val_data=[]\n",
        "val_label = []"
      ],
      "metadata": {
        "id": "eKG3DCEPtSud"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in normal_cases:\n",
        "    image = cv2.imread(str(image))\n",
        "    image = cv2.resize(image, (224,224))\n",
        "    if image.shape[2] ==1:\n",
        "        image = np.dstack([image, image, image])\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image.astype(np.float32)/255\n",
        "    label = to_categorical(0, num_classes=2)\n",
        "    val_data.append(image)\n",
        "    val_label.append(label)"
      ],
      "metadata": {
        "id": "3qh2IoKvMQDS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in pneumonia_cases:\n",
        "    image = cv2.imread(str(image))\n",
        "    image = cv2.resize(image, (224,224))\n",
        "    if image.shape[2] ==1:\n",
        "        image = np.dstack([image, image, image])\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image.astype(np.float32)/255.\n",
        "    label = to_categorical(1, num_classes=2)\n",
        "    val_data.append(image)\n",
        "    val_label.append(label)"
      ],
      "metadata": {
        "id": "uXdMXvpTNU9y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = np.array(val_data)\n",
        "val_label = np.array(val_label)"
      ],
      "metadata": {
        "id": "_rW4h1N9N7OY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "x_test = np.array(x_test) / 255\n",
        "# resize data for deep learning \n",
        "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "UL8TRqYSjPWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = ia.OneOf([\n",
        "    ia.Fliplr(), \n",
        "    ia.Affine(rotate=20), \n",
        "    ia.Multiply((1.2, 1.5))]) "
      ],
      "metadata": {
        "id": "N6dAuldjREAQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_gen(data, batch_size):\n",
        "    # Get total number of samples in the data\n",
        "    n = len(data)\n",
        "    steps = n//batch_size\n",
        "    \n",
        "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
        "    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
        "\n",
        "    indices = np.arange(n)\n",
        "    \n",
        "    i =0\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "        count = 0\n",
        "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
        "        for j, idx in enumerate(next_batch):\n",
        "            img_name = data.iloc[idx]['image']\n",
        "            label = data.iloc[idx]['label']\n",
        "            \n",
        "            encoded_label = to_categorical(label, num_classes=2)\n",
        "\n",
        "            img = cv2.imread(str(img_name))\n",
        "            img = cv2.resize(img, (224,224))\n",
        " \n",
        "            if image.shape[2]==1:\n",
        "                iamge = np.dstack([image, image, image])\n",
        "            \n",
        "            original_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                        \n",
        "            original_image = image.astype(np.float32)/255.\n",
        "            \n",
        "            batch_data[count] = original_image\n",
        "            batch_labels[count] = encoded_label\n",
        "            \n",
        "            if label==0 and count < batch_size-2:\n",
        "                augment_img1 = seq.augment_image(img)\n",
        "                augment_img2 = seq.augment_image(img)\n",
        "                augment_img1 = cv2.cvtColor(augment_img1, cv2.COLOR_BGR2RGB)\n",
        "                augment_img2 = cv2.cvtColor(augment_img2, cv2.COLOR_BGR2RGB)\n",
        "                augment_img1 = augment_img1.astype(np.float32)/255.\n",
        "                augment_img2 = augment_img2.astype(np.float32)/255.\n",
        "\n",
        "                batch_data[count+1] = augment_img1\n",
        "                batch_labels[count+1] = encoded_label\n",
        "                batch_data[count+2] = augment_img2\n",
        "                batch_labels[count+2] = encoded_label\n",
        "                count=count+2\n",
        "            \n",
        "            else:\n",
        "                count=count+1\n",
        "            \n",
        "            if count==batch_size-1:\n",
        "                break\n",
        "            \n",
        "        i+=1\n",
        "        yield batch_data, batch_labels\n",
        "            \n",
        "        if i>=steps:\n",
        "            i=0"
      ],
      "metadata": {
        "id": "FYUxqfI26-8z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def model_build():\n",
        "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
        "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
        "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
        "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
        "    x = BatchNormalization(name='bn1')(x)\n",
        "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
        "    x = BatchNormalization(name='bn2')(x)\n",
        "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
        "    \n",
        "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
        "    x = BatchNormalization(name='bn3')(x)\n",
        "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
        "    x = BatchNormalization(name='bn4')(x)\n",
        "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
        "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
        "    \n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.7, name='dropout1')(x)\n",
        "    x = Dense(512, activation='relu', name='fc2')(x)\n",
        "    x = Dropout(0.5, name='dropout2')(x)\n",
        "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
        "    \n",
        "    model = Model(inputs=input_img, outputs=x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "YWP5ubowPXNy"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  model_build()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "glhVSZ4g-_WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "opt = Adam(lr=0.0001, decay=1e-5)\n",
        "es = EarlyStopping(patience=5)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
      ],
      "metadata": {
        "id": "3PiFwJk4Vr7r"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "nb_epochs = 20\n",
        "\n",
        "train_data_gen = data_gen(data=train_dataframe, batch_size=batch_size)\n",
        "\n",
        "nb_train_steps = train_dataframe.shape[0]//batch_size\n"
      ],
      "metadata": {
        "id": "FdmaKQZ_GvyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_cases_dir = test_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
        "\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "for img in normal_cases:\n",
        "    img = cv2.imread(str(img))\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    if img.shape[2] ==1:\n",
        "        img = np.dstack([img, img, img])\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32)/255.\n",
        "    label = to_categorical(0, num_classes=2)\n",
        "    test_data.append(img)\n",
        "    test_labels.append(label)\n",
        "                      \n",
        "for img in pneumonia_cases:\n",
        "    img = cv2.imread(str(img))\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    if img.shape[2] ==1:\n",
        "        img = np.dstack([img, img, img])\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32)/255.\n",
        "    label = to_categorical(1, num_classes=2)\n",
        "    test_data.append(img)\n",
        "    test_labels.append(label)\n",
        "    \n",
        "\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "print(\"Total number of test examples: \", test_data.shape)\n",
        "print(\"Total number of labels:\", test_labels.shape)"
      ],
      "metadata": {
        "id": "5oXKNqlIG6JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_score = model.evaluate(test_data, test_labels, batch_size=16)\n",
        "print(\"Loss on test set: \", test_loss)\n",
        "print(\"Accuracy on test set: \", test_score)"
      ],
      "metadata": {
        "id": "azjhtq2iHQ0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(test_data, batch_size=16)\n",
        "preds = np.argmax(preds, axis=-1)\n",
        "\n",
        "original_test_labels = np.argmax(test_labels, axis=-1)\n",
        "\n",
        "print(orig_test_labels.shape)\n",
        "print(preds.shape)\n"
      ],
      "metadata": {
        "id": "s9vFYLzVPHSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}